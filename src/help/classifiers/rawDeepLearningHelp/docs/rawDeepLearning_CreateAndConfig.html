<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html>
<head>
<link href="../../../pamHelpStylesheet.css" type="text/css"
	rel="STYLESHEET">
<title>PAMGuard Deep Learning Module - Create and Configure</title>

</head>
<body>
	<h1 id="pamguard-s-deep-learning-module">PAMGuard Deep Learning
		Module</h1>

	<h2 id="creating-an-instance-of-the-module">Creating an instance
		of the module</h2>
	<p>
		The module can be added from the <em>File&gt; Add modules &gt;
			Classifier &gt; Raw deep learning classifier</em> menu or by right
		clicking in the data model. More than one instance of the module can
		be added if multiple deep learning models are required.
	</p>
	<h2 id="module-settings">Module settings</h2>
	<p>
		The module settings are opened by selecting the <em>Settings &gt;
			Raw deep learning classifier</em> menu. The main settings pane is shown
		below and is split into three sections, <em>Raw Sound Data</em>, <em>Segmentation</em>
		and <em>Deep Learning Model</em>
	</p>
	<p align="center">
		<img src="images/deep_leanring_module_help.png">
	</p>

	<p>
		<em>The main settings pane for the deep learning module with
			descriptions</em>
	</p>
	<h3 id="raw-sound-data">Raw Sound Data</h3>
	<p>The deep learning module accepts any raw data source i.e., any
		data source that contains raw waveform data e.g. clicks, clips and
		Ishmael detections. Note that the module accepts whislte and moan
		detections but only if a delphinID classifier has been loaded.</p>
	<p>If the data is continuous, e.g. from the Sound Acquisition
		module then deep learning detections are saved to PAMGuard&#39;s data
		management system if they pass a user defined prediction threshold.
		The raw waveform data for segments which pass prediction threshold is
		saved and the detection is annotated with the deep prediction results.
	</p>
	<p>If the data source is an existing detection data stream, e.g.
		clicks or clips, then the deep learning results are saved as an
		annotation attached each detection. The data is segmented in exactly
		the same way as continuous data and thus, depending on the length of
		raw data within the detection, there can be more than one prediction
		per detection.</p>
	<p>Channel grouping controls are used to arrange channels into
		groups. Channels in the same group are saved together for downstream
		processes. So, for example if channels 0 and 2 are in a group, then
		the raw waveform data from both channel 0 and 2 will be saved and can
		be used in downstream processes, e.g., for localisation.</p>
	<h3 id="segmentation">Segmentation</h3>
	<p>
		The segmentation section defines how the raw data is segmented. Some
		deep learning models require a specific segment size and others can be
		run with different segment sizes. The <em>Window Length</em> is the
		size of the segment in samples. The <em>Hop Length</em> is the overlap
		(from the start of the segment) in samples. A <em>Hop Length</em>
		which is the same as the segment length means no overlap. If a
		prediction passes threshold, then the raw data from segments is saved
		to PAMGuard binary files. If concurrent segments pass a prediction
		threshold, then they are saved as one data unit. The <em>Max.
			re-merge</em> is the maximum number of segments that can form a single
		data unit before a new data unit is automatically created.
	</p>
	<h3 id="deep-learning-model">Deep Learning Model</h3>
	<p>The deep learning model section is used to select the deep
		learning model. The drop down menu is used to select the framework the
		model is from e.g. Generic model. Note that each model type has a
		unique user interface which appears just below the drop down menu -
		currently these all look fairly similar.</p>
	<p>All frameworks require a model file to be selected using the
		browse button (File icon). A wait icon will appear and the model will
		be loaded. If the deep learning model loading is successful then the
		filename of the model will appear (e.g. saved_model.pb)</p>
	<p>
		<em>Note: when a model is first loaded, the computer must be
			connected to the internet as PAMGuard will download the correct
			libraries for the computer to open the specific model. On Windows
			machine these libraries are found in a hidden folder called ai.djl.
			in the user account folder.</em>
	</p>
	<p>Once the model has loaded there some unique options depending on
		the currently selected framework.</p>
	<h4 id="generic-model">Generic Model</h4>
	<p>
		A generic model must be set up via the <em>Advanced</em> menu button.
	</p>
	<p align="center">
		<img src="images/advanced_settings_generic_1.png">
	</p>

	<p>
		<em>Before a sound segment can be classified it must be converted
			into a format suitable for the deep learning model. This is achieved
			by a list of <em>transforms</em> which convert a raw sound data into
			an appropriate format. Usually this involves converting to a
			spectrogram image and then performing a series of noise reductions
			and interpolation step. For the generic model users either have to
			manually add transforms and input the correct settings for each, or
			load a transforms *.pgtr setting file
		</em>
	</p>
	<p>
		The <em>Model Transforms</em> tab in the advanced menu pane allows a
		user to set up a set of transforms. The <em>Add transfrom</em> +
		button adds a transforms and these can be dragged in order using the
		drag handles on the left of each transform. Each transform has
		it&#39;s own settings pane which can be expanded to show transform
		specific settings. The bottom of the advanced settings pane shows a
		preview of the data that will be input into the deep learning model,
		including the shape of the input data e.g. a 100x50 image.
	</p>
	<p align="center">
		<img src="images/advanced_settings_generic_2.png">
	</p>

	<p>
		<em>The Model Settings tab allows the model inputs and outputs to
			be defined</em>
	</p>
	<p>
		The <em>Model Settings</em> tab allows the model input shape and
		output shape/classes to be defined. Most models will have metadata on
		the input and output data and these can be set by selecting the <em>Use
			default model shape</em> and <em>Use default model out</em> switches
		respectively. Otherwise, the input and output shape and the output
		classes must be defined manually
	</p>
	<p>The import and export buttons on the bottom of the advanced
		settings pane can be used to export and import settings for the
		generic model. This means that users do not have to manually set up
		transforms and input and output data whenever settings up a new
		PAMGuard data model and allow easier sharing of classifiers amongst
		researchers.</p>
	<h4 id="koogu-ketos-animalspot-pamguard-zip-and-delphinid-models">Koogu,
		Ketos, AnimalSpot, PAMGuard zip and delphinID models</h4>
	<p>
		If using a deep learning model from a supported framework then all
		transforms are automatically set up. The transforms can be viewed and
		altered via the Advanced menu button but in the majority of cases
		these settings should not be used. For some models, it is advisable to
		select &quot;Use default segment length&quot; to change the <em>Window
			length</em> to the default for the selected model.
	</p>
	<p align="center">
		<img width="700" height="700"
			src="images/advanced_settings_animalspot_1.png">
	</p>

	<p>
		<em>An AnimalSpot, Ketos or other supported deep learning model
			will automatically create a list of transforms with the appropriate
			settings. These is no need to use the advanced pane but it is there
			in case users wish to change transform settings for some reason</em>
	</p>
	<h3 id="default-models">Default Models</h3>
	<p>Default models are selectable from the menu button in the Deep
		Learning Pane. Default models are deep learning classifiers which are
		open source, known to be effective and have have been published in
		open access academic litrature; they are downloaded directly from a
		GitHub repository and then all associated settings are automtically
		applied. The default model selection pane also contains hyperlinks to
		the papers descirbing each model which will take users directly to the
		relvent website.</p>

	<p align="center">
		<img src="images/default_settings_humpback_1.png">
	</p>

	<p>
		<em>Default models can be downloaded. Default models are models
			which are published, open and have been known to work well amongst
			the bioacoustics community. More will be added to PAMGaurd over time.
			If you you would like your model to become a defualt model then drop
			PAMGuard support an email.</em>
	</p>

	<br>
	<br>
	<br>
	<p class="prevLink">
		<a href="rawDeepLearning_overview.html">Previous: Overview</a>
	</p>
	<p class="nextLink">
		<a href="rawDeepLearning_Running.html">Next: Running the Deep
			Learning module</a>
	</p>
	<br>
	<br>
	<br>
</body>
</html>